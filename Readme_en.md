### English README (Based on Project Version)

**File to Upload:** `README.md`  
**Recommended Location:** Project root directory  

```markdown
# Image Captioning System

This project implements an automatic image captioning system using deep learning. It generates natural language descriptions for input images using ResNet as the image encoder and a BERT-style Transformer as the text decoder. Supports COCO and other mainstream datasets, complete with training, inference, and batch processing capabilities for academic and practical applications.

---

## Key Features
- **Deep Neural Architecture**: ResNet152 for image feature extraction + Transformer decoder for text generation
- **BERT-compatible Tokenizer**: Uses standard BERT tokenizer and vocabulary
- **Flexible Configuration**: All parameters configurable via `config.json`
- **Batch Inference**: Processes entire directories of images
- **Mixed Precision & Multi-GPU Training**: Optimized training efficiency
- **COCO Dataset Support**: Built-in data loader for COCO-format datasets

---

## Directory Structure
```

.
‚îú‚îÄ‚îÄ apply.py                # Inference & batch processing
‚îú‚îÄ‚îÄ train.py                # Training script
‚îú‚îÄ‚îÄ model.py                # Model architecture
‚îú‚îÄ‚îÄ new.py                  # Dataset & DataLoader
‚îú‚îÄ‚îÄ config.json             # Configuration file
‚îú‚îÄ‚îÄ checkpoints/            # Saved model weights
‚îú‚îÄ‚îÄ input_images/           # Input images (user-created)
‚îú‚îÄ‚îÄ output_captions/        # Generated captions (auto-created)
‚îî‚îÄ‚îÄ ...

```
---

## Requirements
- Python 3.8+
- PyTorch ‚â• 1.10
- torchvision
- transformers
- Pillow
- pycocotools
- tqdm

Install dependencies (recommended in virtual environment):
```bash
pip install torch torchvision transformers pillow pycocotools tqdm
```

---

## Quick Start

### 1. Configure Settings

Update paths in `config.json` (model weights, tokenizer, input/output directories)

### 2. Generate Captions (Inference)

Place images in `input_images/` and run:

```bash
python apply.py --config config.json
```

Captions will be saved as `.txt` files in `output_captions/`

### 3. Train Model

Prepare COCO-format dataset, update paths in `train.py`, and run:

```bash
python train.py
```

Best model weights auto-saved to `checkpoints/`

---

## Configuration (config.json)

| Parameter             | Description                       |
| --------------------- | --------------------------------- |
| `input_dir`           | Input image directory             |
| `output_dir`          | Output caption directory          |
| `model_path`          | Path to model weights             |
| `tokenizer_path`      | Path to BERT tokenizer            |
| `model_params`        | Transformer architecture settings |
| `image_preprocessing` | Image normalization parameters    |
| `generation`          | Caption generation settings       |
| `device`              | `cuda` or `cpu`                   |

---

## Training & Data Preparation

- Requires COCO-format dataset (images + JSON annotations)
- Custom data loading/augmentation in `new.py`
- Supports multi-GPU training and mixed precision

---

## Acknowledgements

- [PyTorch](https://pytorch.org/)
- [Hugging Face Transformers](https://huggingface.co/transformers/)
- [COCO Dataset](https://cocodataset.org/)

---

## License

For academic/research use only. Commercial use prohibited. Model weights and dataset copyrights belong to original authors.

```
---

### For Installer Version  
If distributing the **installer package** (Nuitka/Inno Setup), use this instead:  
**File to Upload:** `Release_README.md`  
**Recommended Location:** Installer root directory  

```markdown
# Image Captioning System - Installer Edition

Windows installer for automatic image caption generation. Supports batch processing and requires no Python environment.

## Installation
1. Run `ImageCaptioningSetup.exe`
2. Place model weights (`*.pth`) and tokenizer in install directory
3. Update paths in `config.json`
4. Put images in `input_images` folder

## Usage
```bash
cd "C:\Program Files\ImageCaptioning"
ImageCaptioning.exe --config config.json
```

Captions saved to `output_captions/` as text files

[Include remaining sections from original Release_readme.md]

```

---

### Key Recommendations:

1. **GitHub Projects**  
   
   - Use first version (`README.md`) in repository root
   - Add badges (build status, license, Python version)
   - Include visual examples of input/output

2. **Installer Distributions**  
   
   - Use second version (`Release_README.md`) in installer folder
   - Add troubleshooting section for common Windows issues
   - Include screenshot of directory structure

3. **Formatting Tips**  
   
   - Use ```` ```diff ```` for directory trees
   - Add emojis for visual cues (e.g., üìÅ ‚ñ∏ üñºÔ∏è ‚ñ∏ üìù)
   - Include a minimal `config.json` example in code block

Upload as **plain Markdown (.md)** file to appropriate directory.
